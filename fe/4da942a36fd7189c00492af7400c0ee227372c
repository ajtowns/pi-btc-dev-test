From: jlrubin@mit.edu (Jeremy)
Date: Wed, 1 Jul 2015 10:52:16 +0800
Subject: [bitcoin-dev] A possible solution for the block size limit:
 Detection and rejection of bloated blocks by full nodes.
In-Reply-To: <CAPg+sBj2P6ZUxJyrn3Dq76USO5kDTfpkF-zuYsKQbpQbTnyq2A@mail.gmail.com>
References: <CAGpx8BXMfUSaW1FONsbR4dK-uvQ73TjGuh5PUzsxJVwVUW3O1A@mail.gmail.com>
	<CAPg+sBj2P6ZUxJyrn3Dq76USO5kDTfpkF-zuYsKQbpQbTnyq2A@mail.gmail.com>
Message-ID: <CAD5xwhj_cieV18zB-5W+dBse1JQkFqh7t3ofqV3_yf=BgnUq9g@mail.gmail.com>

A simple hack to achieve this would be phase shifting the transaction fees
by one block. There may be other problems, but also potential
benefits, with that though.
This hack works because then a miner would orphan a block which didn't
properly reward them, which makes it very costly for even a miner to put in
a bunch of transactions for free. This phase can be adjusted to different
amounts, spread over multiple blocks, or even randomly selected at the time
of mining from a pool of un-fee claimed blocks (although this would require
some seeding to create a pool of any size greater than 1).

Again, this is probably a bad idea and I haven't thought it through
completely, but just tossing it out there.

Ps sorry if you're seeing this many times I think it bounced due to the
not-subscribed rule (sent from my other account)
On Wednesday, July 1, 2015, Pieter Wuille <pieter.wuille at gmail.com> wrote:

> The problem with this approach is that you need 100% exact behaviour for
> every node on the network in their decision to reject a particular block.
> So we need a 100% mempool synchronization across all nodes - otherwise just
> an attempted double spend could result in a fork in the network because
> some nodes saw it and some didn't. And actually, if we had 100% mempool
> synchronization, we wouldn't need a blockchain in the first place, because
> we could just use "first to enter mempool" as validity criterion.
>
> On Wed, Jul 1, 2015 at 1:41 AM, Peter Grigor <peter at grigor.ws
> <javascript:_e(%7B%7D,'cvml','peter at grigor.ws');>> wrote:
>
>> The block size debate centers around one concern it seems. To wit: if
>> block size is increased malicious miners may publish unreasonably large
>> "bloated" blocks. The way a miner would do this is to generate a plethora
>> of private, non-propagated transactions and include these in the block they
>> solve.
>>
>> It seems to me that these bloated blocks could easily be detected by
>> other miners and full nodes: they will contain a very high percentage of
>> transactions that aren't found in the nodes' own memory pools. This
>> signature can be exploited to allow nodes to reject these bloated blocks.
>> The key here is that any malicious miner that publishes a block that is
>> bloated with his own transactions would contain a ridiculous number of
>> transactions that *absolutely no other full node has in its mempool*.
>>
>> Simply put, a threshold would be set by nodes on the allowable number of
>> non-mempool transactions allowed in a solved block (say, maybe, 50% -- I
>> really don't know what it should be). If a block is published which
>> contains more that this threshold of non-mempool transactions then it is
>> rejected.
>>
>> If this idea works the block size limitation could be completely removed.
>>
>> _______________________________________________
>> bitcoin-dev mailing list
>> bitcoin-dev at lists.linuxfoundation.org
>> <javascript:_e(%7B%7D,'cvml','bitcoin-dev at lists.linuxfoundation.org');>
>> https://lists.linuxfoundation.org/mailman/listinfo/bitcoin-dev
>>
>>
>

-- 
--
@JeremyRubin <https://twitter.com/JeremyRubin>
<https://twitter.com/JeremyRubin>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.linuxfoundation.org/pipermail/bitcoin-dev/attachments/20150701/58eeb253/attachment.html>
